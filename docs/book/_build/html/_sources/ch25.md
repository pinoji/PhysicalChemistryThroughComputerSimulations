#  Proof of Uncertainty Principle

## Setting Up The Transform

Any physical state will have a probability distribution
$\Phi (p)\& \psi(x)$ in momentum and position spcae, respectively.
Consider collection of eigen function
$\left\{  e^{ip \frac{x}{\hbar}} \right\}$ where
$p \text{ in the vector space }\R$\

$\hat{p}e^{ip \frac{x}{\hbar}} = -i \hbar \frac{d}{dx} e^{ip \frac{x}{\hbar}}$\
= $p e^{ip \frac{x}{\hbar}}$\
Realizing this uncountable collection of function forms a complete basis
set. If one is interested in representing the same state in position
variable x, we need to sum up all of these function with probability
density $\Phi (p)$

$$\begin{equation*}
\begin{split}
& \psi(x) = \frac{1}{\sqrt {2\pi\hbar}}\int \Phi (p)e^{ip \frac{x}{\hbar}} dp \rightarrow \text{position distribution of the same state}\\
\end{split}
\end{equation*}$$ We will explain constant later. At this point,
consider how to obtain $\Phi (p)$ from $\psi (x)$. This can be achieved
by multiplying $\psi (x)$ by $e^{-ip' \frac{x}{\hbar}}$ for some p'
followed by integration w.r.t. x.\
$$\begin{equation*}
\begin{split}
& \int \psi (x)e^{-ip' \frac{x}{\hbar}} dx \\
& = \frac{1}{\sqrt {2\pi\hbar}} \int \int \Phi (p)e^{ip \frac{x}{\hbar}}e^{-ip' \frac{x}{\hbar}} dpdx \\
& = \frac{1}{\sqrt {2\pi\hbar}} \int \Phi (p) \int e^{i(p-p') \frac{x}{\hbar}} dxdp \\
& \text{Using Lemma}\\
& = \frac{1}{\sqrt {2\pi\hbar}} \int \Phi (p) \delta (p-p')2\pi\hbar dp \\
& = \frac{1}{\sqrt {2\pi\hbar}} 2\pi\hbar \Phi (p')  \\
& \text{By  replace p' with p}\\
& \Phi (p) = \frac{1}{\sqrt {2\pi\hbar}} \int \psi (x) e^{-ip \frac{x}{\hbar}}dx  \\
\end{split}
\end{equation*}$$ Note that we choose the constant
($\frac{1}{\sqrt {2\pi\hbar}}$) to be symmetric going from $\Phi(p)$ to
$\psi(x)$, $\&$ from $\psi(x)$ to $\Phi(p)$.

##  Lemma: $2$$\pi$$\hbar$ $\delta(p-p')$$=$$\int$ $e^{i(p-p')\frac{x}{\hbar}}$$dx$

Again we use the same transform definition

$$\begin{equation*}
\begin{split}
& \psi(x) = \frac{1}{\sqrt {2\pi\hbar}}\int \Phi (p)e^{ip \frac{x}{\hbar}} dp \\
& \Phi (p) = \frac{1}{\sqrt {2\pi\hbar}} \int \psi (x) e^{-ip \frac{x}{\hbar}}dx  \\
& \text {denote } \hat {\psi}(x) =\Phi(p) \\
& \text {then} \\
& \hat {f}(p') = \frac{1}{\sqrt {2\pi\hbar}} \int f(x)e^{-ip' \frac{x}{\hbar}} dx \\
& = \frac{1}{\sqrt {2\pi\hbar}} \int   \frac{1}{\sqrt {2\pi\hbar}}\int \hat{f}(p)e^{ip \frac{x}{\hbar}}dp e^{-ip' \frac{x}{\hbar}}dx \\
& =  \int \hat{f}(p)\left(\frac{1}{2\pi\hbar}\int e^{i(p-p') \frac{x}{\hbar}}dx\right)dp \\
\end{split}
\end{equation*}$$

By the definition of the delta function $f(p')= \int \delta(p-p')f(p)dp$
we obtain the desired result\
$$\begin{equation*}
\begin{split}
 \delta(p-p') = \frac{1}{2\pi\hbar} \int  e^{i(p-p')\frac{x}{\hbar}}dx\\
\end{split}
\end{equation*}$$

## Plancherel Theorem for Position and Momentum Pair

So far we have defined transform $$\begin{equation*}
\begin{split}
& \psi(x) = \frac{1}{\sqrt {2\pi\hbar}}\int \Phi (p)e^{ip \frac{x}{\hbar}} dp \\
& \Phi (p) = \frac{1}{\sqrt {2\pi\hbar}} \int \psi (x) e^{-ip \frac{x}{\hbar}}dx  \\
& \text {denote } \hat {\psi}(x) =\Phi(p) \\
\end{split}
\end{equation*}$$ Let $f(x)$ & $g(x)$ be the probability distribution of
x\
Let us consider the inner product

$$\begin{equation*}
\begin{split}
& \int f(x)g^*(x)dx \\
& \text {using the transform defined above}\\
& = \int f(x)\frac{1}{\sqrt {2\pi\hbar}}\int \left( \hat{g}(p)e^{ip \frac{x}{\hbar}}\right)^* dp dx \\
& = \int f(x)\frac{1}{\sqrt {2\pi\hbar}}\int  \hat{g^*}(p)e^{-ip \frac{x}{\hbar}} dp dx \\
& = \int \hat{g^*}(p) \frac{1}{\sqrt {2\pi\hbar}}\int f(x) e^{-ip \frac{x}{\hbar}} dx dp \\
& = \int \hat{g^*}(p) \hat {f}(p) dp \\
& \text {Setting f = g at the beggining}\\
& \int \left| f(x)\right|^2 dx = \int \left| \hat {f} (p)\right|^2 dp \\
\end{split}
\end{equation*}$$

##  Uncertainty Principle: Distribution Centered at Zero

Consider the case where both $\Phi(p)$ & $\psi(x)$ are centered at
zero.\
$$\begin{equation*}
\begin{split}
& 1 = \int \left| \psi (x)\right| ^2 dx \\
& \text{Perform integration by parts by setting }\\
& u = \left| \psi (x)\right| ^2 = \psi^* (x)\psi (x)\\
& du =  \psi^{*'} (x)\psi (x)+\psi^* (x)\psi ^{'}(x) = 2Re(\psi^{*'} (x)\psi (x))\\
& v = x,  dv = dx \\
& = -2Re \int x \psi^{*'} (x)\psi (x) dx \\
& \leq 2\left| \int x \psi^{*'} (x)\psi (x) dx\right|  \\
& \text{By Cauchy-Schwarz inequality}\\
& \leq  2\left(\int \left|x \psi (x)\right|^2 dx \right)^{\frac{1}{2}}  \left(\int \left| \psi '(x)\right|^2 dx \right)^{\frac{1}{2}}  \\
& = 2\left(\int x^2\left| \psi (x)\right|^2 dx \right)^{\frac{1}{2}}  \left(\int \left| \psi '(x)\right|^2 dx \right)^{\frac{1}{2}}  \\
& =  2\sigma _x  \left(\int \left| \psi '(x)\right|^2 dx \right)^{\frac{1}{2}}  \rightarrow \text{ eq. A1 } \\
& \text{Also,}\\
&  \psi '(x) =\frac{d}{dx}\psi(x)  = \frac{1}{\sqrt {2\pi\hbar}} \int \Phi (p)\frac{d}{dx} e^{ip \frac{x}{\hbar}}dx  \\
& = \frac{1}{\sqrt {2\pi\hbar}} \int  \left(\frac{ip}{\hbar}\Phi (p) \right)\ e^{ip \frac{x}{\hbar}}dp  \\
& \text{By applying the Plancherel Theorem $\int \left| f(t)\right|^2 dt = \int \left| \hat {f} (\omega)\right|^2 d\omega $}\\
&  \left(\int \left| \psi '(x)\right|^2 dx \right)^{\frac{1}{2}} = \left(\int \left| \left(\frac{ip}{\hbar}\Phi (p) \right)\right|^2 dp \right)^{\frac{1}{2}} \\
&  = \frac{1}{\hbar}\left(\int p^2\left| \left(\Phi (p) \right)\right|^2 dp \right)^{\frac{1}{2}} \\
& =  \frac{1}{\hbar}\sigma _p 
\end{split}
\end{equation*}$$ $$\begin{equation*}
\begin{split}
& \text{from Eq A1}\\
& 1 \leq  2\sigma _x  \left(\int \left| \psi '(x)\right|^2 dx \right)^{\frac{1}{2}} = \frac{2}{\hbar}\sigma _x\sigma _p \\
& \text{Hence}\\
& \frac{\hbar}{2}\leq\sigma _x\sigma _p \\
\end{split}
\end{equation*}$$

##  Uncertainty Principle: Distribution Centered at Nonzero

Now consider $\psi(x)$ & $\Phi(p)$ which may have nonzero average value\
Let $\Psi(x)=e^{-i\frac{m_p}{\hbar}x}\psi(x)$\
$$\begin{equation*}
\begin{split}
& \text{Because }\left|\Psi(x)\right|=\left|\psi(x)\right|\\
& 1 = \int \left| \Psi (x)\right| ^2 dx \\
& \text{Perform integration by parts by setting }\\
& u = \left| \Psi (x)\right| ^2 = \Psi^* (x)\Psi (x)\\
& du =  \Psi^{*'} (x)\Psi (x)+\Psi^* (x)\Psi ^{'}(x) = 2Re(\Psi^{*'} (x)\Psi (x))\\
& v = x-\mu_x,  dv = dx \\
& = -2Re \int (x-\mu_x)\left| \Psi (x)\right| ^2dx\\
& \leq 2\left(\int \left| (x-\mu_x)^2\Psi (x)\right|^2 dx \right)^{\frac{1}{2}}  \left(\int \left| \Psi '(x)\right|^2 dx \right)^{\frac{1}{2}}  \\
& \text{By same approach: Applying the Plancherel Theorem on last parentheses}\\
& \leq 2\sigma _x  \left(\int \left|\frac{i(p-\mu_p)}{\hbar} \hat {\Psi^ {'}}(x)\right|^2 dx \right)^{\frac{1}{2}} \\
& = \frac {2\sigma _x  \sigma_p}{\hbar} \\
& \text {Therefore $\frac{\hbar}{2}\leq\sigma _x\sigma _p $ as desired}
\end{split}
\end{equation*}$$

## Uncertainty Principle Proof using Commutator 

By the definition of Variance,\
$$\begin{equation*}
\begin{split}
& \sigma _A ^2 = \int  \Psi^{*} (x)\left(   \hat{A} - \left<  A\right>    \right) ^2 \Psi (x)dx \\
&\text{HW:  It is good exercise to get to the next line}\\
& = \int  \Psi^{*} (x)  \hat{A}^2 \Psi (x)dx - \left<  A\right>^2   \\
&\text{Similarly, you can get } \sigma _B ^2 = \int  \Psi^{*} (x)  \hat{B}^2 \Psi (x)dx - \left<  B\right>^2   \\
&\text{Let  } f(x)= \left( \left(   \hat{A} - \left<  A\right>    \right) \Psi (x) \right) \text{  and    } g(x)= \left( \left(   \hat{B} - \left<  B\right>    \right) \Psi (x) \right) \\ 
& \sigma _A ^2 = \int  \left( \left(   \hat{A} - \left<  A\right>    \right) \Psi (x) \right) \left( \left(   \hat{A} - \left<  A\right>    \right) \Psi (x) \right)^{*} dx =  \int  f (x) f^{*}(x) dx  \text{  in  } \R \\
& \sigma _B ^2 = \int  \left( \left(   \hat{B} - \left<  B\right>    \right) \Psi (x) \right) \left( \left(   \hat{B} - \left<  B\right>    \right) \Psi (x) \right)^{*} dx =  \int  g (x) g^{*}(x) dx  \text{  in  } \R \\
& \text{Let us consider  quantity }  z=x+yi=\int  f (x) g^{*}(x) dx  \text{ which is not necessary in  } \R  \text{   but in   } \mathbb{C} \\
& \text{Then, the complex conjugate of z is }  z^{*}=x-yi=\int  g (x) f^{*}(x) dx  \\
& z = \int  \left( \left(   \hat{A} - \left<  A\right>    \right) \Psi (x) \right) \left( \left(   \hat{B} - \left<  B\right>    \right) \Psi (x) \right)^{*} dx= \int  \Psi^{*} (x)  \hat{A}  \hat{B} \Psi(x)dx - \left<  A\right>\left<  B\right> \\
& \text{Similarly,  } z^{*}= \int  \Psi^{*} (x)  \hat{B}  \hat{A} \Psi(x)dx - \left<  A\right>\left<  B\right> \\
& \text{Since} \left| z \right| ^2 = x^2+y^2 \text{where x and y are in } \R \text{.  This means that } z^2 \geq y^2 =\left(\frac{z-z^{*}}{2i}\right)^2\\
& \text{Therefore,  }  \left| z \right| ^2 = \geq y^2 = \left( \frac{\int  \Psi^{*} (x)  \left( \hat{A}  \hat{B}-\hat{B}  \hat{A} \right) \Psi(x)dx }{2i} \right)^2= \left( \frac{\int  \Psi^{*} (x)  \left[ \hat{A} ,  \hat{B} \right] \Psi(x)dx }{2i} \right)^2\\
&\text{Using Cauchy-Schwarz inequality,   }  \int  f (x) f^{*}(x) dx  \int  g (x) g^{*}(x) dx \geq  \left| \int  f (x) g^{*}(x) dx \right|^2\\
& \sigma _A ^2  \sigma _B^2 \geq z^2 \geq y^2\\
&\text{for the case the operator does not commute like }\left[ \hat{p_x},\hat{x}\right]= \hat{p_x}\hat{x}-\hat{x}\hat{p_x}=i\hbar\\
& \text {Above inequality will yeild $\frac{\hbar}{2}\leq\sigma _x\sigma _p $ as desired. //}\\
\end{split}
\end{equation*}$$

## Average Volume of a State

Now that we have studied uncertainty principle, we are going to think
about the average volume occupied by a single state. The volume of
single state ($h^3$) is used in part II of this textbook and it is
fundamental to statistical mechanics. Although average volume is
sometimes stated as a direct consequence of uncertinty principle,
average volume is slightly larger than the minimum volume \[cube of the
uncertainty bound ($\left(\hbar/2 \right)^3$)\]. We will derive the
volume from transform defined in previous page.\
$$\begin{equation*}
\begin{split}
& \psi(x) = \frac{1}{\sqrt {2\pi\hbar}}\int \Phi (p)e^{ip \frac{x}{\hbar}} dp \\
& \Phi (p) = \frac{1}{\sqrt {2\pi\hbar}} \int \psi (x) e^{-ip \frac{x}{\hbar}}dx  \\
%& \text {denote } \hat {\psi}(x) =\Phi(p) \\
\end{split}
\end{equation*}$$ Consider 1-D problem. Since we want to avoid a
complete specification of $p$ or $x$, we define converging sequence of
function $\tilde{\delta}$ which approaches to $\delta$. We assume $\psi$
is sufficiently smooth. Keep in mind that we can not specify $p$ and $x$
simalteniously. However, we can restrict the domain of x ($\Omega$) so
that it represent the single state. Consider $\psi^o(x;p)$ which is
identical to $\psi$ within the single state region
$\Omega_x \times \Omega_p$ and zero everywhere else. Let momentum
$\tilde{p'}$ represent the value approximately close to some momentum
$p'$ within this region.\
$$\begin{equation*}
\begin{split}
& \int_{\Omega_x}\psi^o(x;\tilde{p'})e^{-i\tilde{p'} \frac{x}{\hbar}}dx = \int_{\Omega_x}\left( \frac{1}{\sqrt {2\pi\hbar}}\int_{\Omega_p} \Phi^o (p)e^{ip \frac{x}{\hbar}}\tilde{\delta}\left( p-p'  \right) dp \right)e^{-i\tilde{p'} \frac{x}{\hbar}}dx\\
%& \text{With some small error, above can be rewritten as}\\
& = \frac{1}{\sqrt {2\pi\hbar}}\int_{\Omega_x}\Phi^o (\tilde{p'})e^{i\tilde{p'} \frac{x}{\hbar}}e^{-i\tilde{p'} \frac{x}{\hbar}}dx\\
& = \frac{1}{2\pi\hbar}\int_{\Omega_x} \left( \int_{\Omega_x} \psi^o (x;\tilde{p'}) e^{-i\tilde{p'} \frac{x}{\hbar}}dx\right)dx\\
& = \frac{1}{2\pi\hbar} \left( \int_{\Omega_x} \psi^o (x;\tilde{p'}) e^{-i\tilde{p'} \frac{x}{\hbar}}dx\right)\Delta x\\
%& = \frac{1}{2\pi\hbar} \psi(\tilde{x};\tilde{p'})\Delta x \Delta x\\
\end{split}
\end{equation*}$$ Rearrange the equation to obtain, $$\begin{equation*}
\begin{split}
& 2\pi\hbar=h= \Delta x    \hspace{50pt}   \text{in 1-D}\\
\end{split}
\end{equation*}$$ Average volume of a single state in 3-D ($h^3$) is
simply a cube of the 1-D result.//\

## Euler Equation

We have shown that $S$ and $V$ is extensive variables and $U$ is
extensive function of these variables. More specifically, all of these
are additive (linear relation to size). For this reason, it is obvious
that following relation holds\
$$\ U(aS,aV)=aU(S,V)$$ This equation can interprit as \"if the new
system has twice the volume (a=2) and entropy per volume is unchanged,
internal energy is twice as large as original system.\" Then, it follwos
that\
$$\begin{equation*}
\begin{split}
 \frac{dU(aS,aV)}{da}&=U(S,V)\\
&=\left( \frac{\partial U(aS,aV)}{\partial (aS)}     \right)_V \frac{d \left(aS\right)}{da}+\left( \frac{\partial U(aS,aV)}{\partial (aV)}     \right)_S \frac{d \left(aV\right)}{da}\\
&=\left( \frac{\partial U(aS,aV)}{\partial (aS)}     \right)_V S+\left( \frac{\partial U(aS,aV)}{\partial (aV)}     \right)_S V\\
& \text{by setting a=1}\\
&=\left( \frac{\partial U(S,V)}{\partial S}\right)_V S+\left( \frac{\partial U(S,V)}{\partial V}     \right)_S V\\
& \text{from 1st law} \\
& dU(S,T)=\left( \frac{\partial U(S,V)}{\partial S}\right)_VdS+\left( \frac{\partial U(S,V)}{\partial V}\right)_SdV=\delta q+ \delta w =Tds-Pdv\\
& \text{ first and second partial derivatives are $T$ and  $-P$, respectively }\\
& U= TS-PV\\
\end{split}
\end{equation*}$$ It folllows from the argument in the text, U is a
state function. This argument can be repeated for $U(S,V,N)$.\

## Lagrange Multipliers and Chemical Potential

### Single component system

At the beginning of this semester, we used Lagrange multiplier to obtain
Boltzmann thermal distribution with 2 constraints:\
$$\begin{align*}
\delta N_i=\sum\limits_i \delta N_i = 0 \cdots \text{\circled{1}}\\
\delta N_i= \sum\limits_i \delta  N_i\epsilon_i=0 \cdots \text{\circled{2}}
\end{align*}$$

When we try to maximize $\ln\Omega$\

$e^{-1}$ is going to be cancelled in $Z \Rightarrow$ can be eliminated.
From discussion in the text, $\beta=1/k_BT$. Since alpha is a pure
number, the chemical potential has a unit of energy as expected.

### Multi-component system

Consider system composed of two chemical components. The constraint we
have for such system is $$\begin{align*}
\delta N_1=\sum\limits_i \delta N_{1i} =0  \cdots \text{\circled{1}}\\
\sum\limits_i N_{2i} = N_2 \cdots \text{\circled{2}}\\
\sum\limits_{i} N_{1i}\epsilon_{i}=E_1 \cdots \text{\circled{3}}\\
\sum\limits_{j} N_{2j}\epsilon_{j}=E_2 \cdots \text{\circled{4}}\\
\end{align*}$$

consider $\Omega$
$$\Omega=\frac{N_1}{N_{10}N_{11}N_{12}\cdots N_{1r-1}}\frac{N_2}{N_{20}N_{21}N_{22}\cdots N_{2s-1}}$$
Since constant term disappear in the next step, we can ignore constants
$$\ln{\Omega}=-\sum\limits_i N_{1i}\ln{N_{1i}}-\sum\limits_j N_{2j}\ln{N_{2j}}$$
$$\delta\ln{\Omega}=-\sum\limits_i \delta N_{1i}\ln{N_{1i}} -\sum\limits_i \delta N_{1i} -\sum\limits_j \delta N_{2j}\ln{N_{2j}}-\sum\limits_j \delta N_{2j}$$
Following the similar step as in single component, we introduce the
Lagrange multiplier\
$$\delta L = \sum\limits_i (1+\ln N_i + \alpha_1 + \beta_1 \epsilon_i)\delta N_i =0=\sum\limits_j (1+\ln N_j + \alpha_2 + \beta_2 \epsilon_j)\delta N_j$$
Since LHS and RHS is independent, inside the parentheses must be zero.\
$$(1+\ln N_i + \alpha_1 + \beta_1 \epsilon_i)=0=-(1+\ln N_j + \alpha_2 + \beta_2 \epsilon_j)$$
Since each components are thermal equilibrium with thermal bath, namely
$\beta_1=\beta=1/k_BT=\beta_2$,\
$$\ln{N_iN_j}=-2-\alpha_1-\alpha_2-\beta(\epsilon_i+\epsilon_j)$$ Then,\
$$N_{1i}N_{2j}=e^{-2-\alpha_1-\alpha_2-\beta(\epsilon_i+\epsilon_j)}=e^{-2}e^{-\beta([\epsilon_i+\alpha_1/\beta]+[\epsilon_j+\alpha_2/\beta])}$$
$$N_1N_2=e^{-2}\sum\limits_{ij}e^{-\beta(\epsilon_i+\epsilon_j+\alpha_1/\beta+\alpha_2/\beta)}$$
$$P(i,j)=\frac{N_{1i}N_{2j}}{N_1N_2}=\frac{e^{-\beta([\epsilon_i+\alpha_1/\beta]+[\epsilon_j+\alpha_2/\beta])}}{\sum\limits_{ij}e^{-\beta([\epsilon_i+\alpha_1/\beta]+[\epsilon_j+\alpha_2/\beta])}}$$
and chemical potentials for each components are reltate to Lagrange
multipliers.\
$$\mu_1=\alpha_1/\beta\text{  and  }\mu_2=\alpha_2/\beta$$ This chemical
potential offset the base erengy of each chemical components and it is
generally determined by the position of atoms.\
